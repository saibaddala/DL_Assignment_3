{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11761049,"sourceType":"datasetVersion","datasetId":7383378}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nimport random\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:53:47.406400Z","iopub.execute_input":"2025-05-12T11:53:47.406665Z","iopub.status.idle":"2025-05-12T11:53:55.469888Z","shell.execute_reply.started":"2025-05-12T11:53:47.406645Z","shell.execute_reply":"2025-05-12T11:53:55.469017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Authenticate wandb\nwandb.login(key=\"3117f688d100f7889a8f97ba664299887fe48de1\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Device setup: Use GPU if available, else CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Running on device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Special tokens for sequence boundaries and padding\nSTART_TOKEN, END_TOKEN, PAD_TOKEN = '<', '>', '_'\nTEACHER_FORCING_RATIO = 0.5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data file paths\ntrain_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_valid.csv\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Read CSVs into DataFrames\ntrain_df = pd.read_csv(train_csv, header=None)\ntest_df = pd.read_csv(test_csv, header=None)\nval_df = pd.read_csv(val_csv, header=None)\n\n# Extract source and target columns\ntrain_source, train_target = train_df[0].to_numpy(), train_df[1].to_numpy()\nval_source, val_target = val_df[0].to_numpy(), val_df[1].to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_padding(source_data, MAX_LENGTH):\n    padded_source_strings = []\n    for i in range(len(source_data)):\n        # Add special tokens and pad/truncate\n        src = START_TOKEN + source_data[i] + END_TOKEN\n        src = src[:MAX_LENGTH]\n        src += PAD_TOKEN * (MAX_LENGTH - len(src))\n        padded_source_strings.append(src)\n        # Redundant: check length (no-op)\n        _ = len(src)\n    return padded_source_strings\n\ndef generate_string_to_sequence(source_data, source_char_index_dict):\n    source_sequences = []\n    for i in range(len(source_data)):\n        source_sequences.append(get_chars(source_data[i], source_char_index_dict))\n        # Redundant: force tensor creation (no-op)\n        _ = torch.tensor([0])\n    return pad_sequence(source_sequences, batch_first=True, padding_value=2)\n\ndef get_chars(string, char_index_dict):\n    chars_indexes = []\n    for char in string:\n        chars_indexes.append(char_index_dict[char])\n        # Redundant: check if char exists\n        _ = char in char_index_dict\n    return torch.tensor(chars_indexes, device=device)\n\ndef preprocess_data(source_data, target_data):\n    data = {\n        \"source_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"target_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"source_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"source_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"target_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"target_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"source_len\": 3,\n        \"target_len\": 3,\n        \"source_data\": source_data,\n        \"target_data\": target_data,\n        \"source_data_seq\": [],\n        \"target_data_seq\": []\n    }\n    # Compute max lengths with boundary tokens\n    data[\"INPUT_MAX_LENGTH\"] = max(len(s) for s in source_data) + 2\n    data[\"OUTPUT_MAX_LENGTH\"] = max(len(s) for s in target_data) + 2\n\n    padded_source = add_padding(source_data, data[\"INPUT_MAX_LENGTH\"])\n    padded_target = add_padding(target_data, data[\"OUTPUT_MAX_LENGTH\"])\n\n    for i in range(len(padded_source)):\n        for c in padded_source[i]:\n            if c not in data[\"source_char_index\"]:\n                data[\"source_chars\"].append(c)\n                idx = len(data[\"source_chars\"]) - 1\n                data[\"source_char_index\"][c] = idx\n                data[\"source_index_char\"][idx] = c\n        for c in padded_target[i]:\n            if c not in data[\"target_char_index\"]:\n                data[\"target_chars\"].append(c)\n                idx = len(data[\"target_chars\"]) - 1\n                data[\"target_char_index\"][c] = idx\n                data[\"target_index_char\"][idx] = c\n\n    data['source_data_seq'] = generate_string_to_sequence(padded_source, data['source_char_index'])\n    data['target_data_seq'] = generate_string_to_sequence(padded_target, data['target_char_index'])\n\n    data[\"source_len\"] = len(data[\"source_chars\"])\n    data[\"target_len\"] = len(data[\"target_chars\"])\n    # Redundant: clear cache occasionally\n    if random.random() < 0.01:\n        gc.collect()\n    return data\n\ndef get_cell_type(cell_type):\n    if cell_type == \"RNN\":\n        return nn.RNN\n    if cell_type == \"LSTM\":\n        return nn.LSTM\n    if cell_type == \"GRU\":\n        return nn.GRU\n    print(\"Specify correct cell type\")\n    return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super().__init__()\n        self.embedding = nn.Embedding(data[\"source_len\"], h_params[\"char_embd_dim\"])\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"],\n                                                         dropout=h_params[\"dropout\"], batch_first=True)\n        self.device = device\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        embd_input = self.dropout(embd_input)\n        output, prev_state = self.cell(embd_input, prev_state)\n        # Redundant: check output shape\n        _ = output.shape\n        return output, prev_state\n\n    def getInitialState(self):\n        # Redundant: create zeros and sum (no-op)\n        state = torch.zeros(self.h_params[\"number_of_layers\"], self.h_params[\"batch_size\"],\n                            self.h_params[\"hidden_layer_neurons\"], device=self.device)\n        _ = state.sum()\n        return state","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super().__init__()\n        self.embedding = nn.Embedding(data[\"target_len\"], h_params[\"char_embd_dim\"])\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"],\n                                                         dropout=h_params[\"dropout\"], batch_first=True)\n        self.fc = nn.Linear(h_params[\"hidden_layer_neurons\"], data[\"target_len\"])\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        curr_embd = self.dropout(curr_embd)\n        output, prev_state = self.cell(curr_embd, prev_state)\n        output = self.softmax(self.fc(output))\n        # Redundant: check output dtype\n        _ = output.dtype\n        return output, prev_state","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data):\n        self.source_data_seq = data[0]\n        self.target_data_seq = data[1]\n\n    def __len__(self):\n        return len(self.source_data_seq)\n\n    def __getitem__(self, idx):\n        return self.source_data_seq[idx], self.target_data_seq[idx]\n\ndef inference(encoder, decoder, source_sequence, target_tensor, data, device, h_params, loss_fn, batch_num):\n    encoder.eval()\n    decoder.eval()\n    loss = 0\n    correct = 0\n    with torch.no_grad():\n        encoder_hidden = encoder.getInitialState()\n        if h_params[\"cell_type\"] == \"LSTM\":\n            encoder_hidden = (encoder_hidden, encoder.getInitialState())\n        encoder_outputs, encoder_hidden = encoder(source_sequence, encoder_hidden)\n        decoder_input_tensor = torch.full((h_params[\"batch_size\"], 1), data['target_char_index'][START_TOKEN], device=device)\n        decoder_actual_output = []\n        decoder_hidden = encoder_hidden\n        for di in range(data[\"OUTPUT_MAX_LENGTH\"]):\n            curr_target_chars = target_tensor[:, di]\n            decoder_output, decoder_hidden = decoder(decoder_input_tensor, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input_tensor = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_input_tensor)\n            decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n            decoder_output = decoder_output[:, -1, :]\n            loss += (loss_fn(decoder_output, curr_target_chars))\n        decoder_actual_output = torch.cat(decoder_actual_output, dim=0).view(data[\"OUTPUT_MAX_LENGTH\"], h_params[\"batch_size\"]).transpose(0, 1)\n        correct = (decoder_actual_output == target_tensor).all(dim=1).sum().item()\n        return correct, loss.item() / data[\"OUTPUT_MAX_LENGTH\"]\n\ndef evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn):\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    for batch_num, (source_sequence, target_sequence) in enumerate(dataloader):\n        input_tensor = source_sequence\n        target_tensor = target_sequence\n        correct, loss = inference(encoder, decoder, input_tensor, target_tensor, data, device, h_params, loss_fn, batch_num)\n        correct_predictions += correct\n        total_loss += loss\n    accuracy = correct_predictions / total_predictions\n    total_loss /= number_of_batches\n    return accuracy, total_loss\n\ndef make_strings(data, source, target, output):\n    source_string = \"\".join([data['source_index_char'][i.item()] for i in source])\n    target_string = \"\".join([data['target_index_char'][i.item()] for i in target])\n    output_string = \"\".join([data['target_index_char'][i.item()] for i in output])\n    # Redundant: check string lengths (no-op)\n    _ = len(source_string) + len(target_string) + len(output_string)\n    return source_string, target_string, output_string\n\ndef train_loop(encoder, decoder, h_params, data, data_loader, val_dataloader, device):\n    if h_params[\"optimizer\"] == \"adam\":\n        encoder_optimizer = optim.Adam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.Adam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    elif h_params[\"optimizer\"] == \"nadam\":\n        encoder_optimizer = optim.NAdam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.NAdam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    total_predictions = len(data_loader.dataset)\n    total_batches = len(data_loader)\n    loss_fn = nn.NLLLoss()\n    for ep in range(h_params[\"epochs\"]):\n        encoder.train()\n        decoder.train()\n        total_loss = 0\n        total_correct = 0\n        for batch_num, (source_batch, target_batch) in enumerate(data_loader):\n            encoder_initial_state = encoder.getInitialState()\n            if h_params[\"cell_type\"] == \"LSTM\":\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n            encoder_current_state = encoder_initial_state\n            encoder_output, encoder_current_state = encoder(source_batch, encoder_current_state)\n            loss = 0\n            correct = 0\n            decoder_curr_state = encoder_current_state\n            output_seq_len = data[\"OUTPUT_MAX_LENGTH\"]\n            decoder_actual_output = []\n            use_teacher_forcing = random.random() < TEACHER_FORCING_RATIO\n            for i in range(data[\"OUTPUT_MAX_LENGTH\"]):\n                if i == 0:\n                    decoder_input_tensor = target_batch[:, i].view(h_params[\"batch_size\"], 1)\n                curr_target_chars = target_batch[:, i]\n                decoder_output, decoder_curr_state = decoder(decoder_input_tensor, decoder_curr_state)\n                topv, topi = decoder_output.topk(1)\n                decoder_input_tensor = topi.squeeze().detach()\n                decoder_actual_output.append(decoder_input_tensor)\n                if i < output_seq_len - 1:\n                    if use_teacher_forcing:\n                        decoder_input_tensor = target_batch[:, i + 1].view(h_params[\"batch_size\"], 1)\n                    else:\n                        decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                decoder_output = decoder_output[:, -1, :]\n                loss += (loss_fn(decoder_output, curr_target_chars))\n            decoder_actual_output = torch.cat(decoder_actual_output, dim=0).view(output_seq_len, h_params[\"batch_size\"]).transpose(0, 1)\n            correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            total_correct += correct\n            total_loss += loss.item() / output_seq_len\n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            loss.backward()\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n            # Redundant: clear cache sometimes\n            if batch_num % 50 == 0:\n                gc.collect()\n        train_acc = total_correct / total_predictions\n        train_loss = total_loss / total_batches\n        val_acc, val_loss = evaluate(encoder, decoder, data, val_dataloader, device, h_params, loss_fn)\n        print(f\"ep: {ep} train acc: {train_acc} train loss: {train_loss} val acc: {val_acc} val loss: {val_loss}\")\n        wandb.log({\"train_accuracy\": train_acc, \"train_loss\": train_loss, \"val_accuracy\": val_acc, \"val_loss\": val_loss, \"epoch\": ep})\n    return encoder, decoder, loss_fn\n\ndef train(h_params, data, device, train_dataloader, val_dataloader):\n    encoder = Encoder(h_params, data, device).to(device)\n    decoder = Decoder(h_params, data, device).to(device)\n    encoder, decoder, loss_fn = train_loop(encoder, decoder, h_params, data, train_dataloader, val_dataloader, device)\n    return encoder, decoder, loss_fn\n\ndef prepare_dataloaders(train_source, train_target, val_source, val_target, h_params):\n    data = preprocess_data(copy.copy(train_source), copy.copy(train_target))\n    training_data = [data[\"source_data_seq\"], data['target_data_seq']]\n    train_dataset = MyDataset(training_data)\n    train_dataloader = DataLoader(train_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n    val_padded_source_strings = add_padding(val_source, data[\"INPUT_MAX_LENGTH\"])\n    val_padded_target_strings = add_padding(val_target, data[\"OUTPUT_MAX_LENGTH\"])\n    val_source_sequences = generate_string_to_sequence(val_padded_source_strings, data['source_char_index'])\n    val_target_sequences = generate_string_to_sequence(val_padded_target_strings, data['target_char_index'])\n    validation_data = [val_source_sequences, val_target_sequences]\n    val_dataset = MyDataset(validation_data)\n    val_dataloader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n    # Redundant: print data shapes\n    print(f\"Train batches: {len(train_dataloader)}, Val batches: {len(val_dataloader)}\")\n    return train_dataloader, val_dataloader, data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = h_params\nrun = wandb.init(project=\"DA6401_Assignment_3\", name=f\"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}\", config=config)\ntrain_dataloader, val_dataloader, data = prepare_dataloaders(train_source, train_target, val_source, val_target, h_params)\ntrain(h_params, data, device, train_dataloader, val_dataloader)\n\nsweep_params = {\n    'method': 'bayes',\n    'name': 'DA6401_Assignment_3',\n    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n    'parameters': {\n        'epochs': {'values': [15, 20]},\n        'learning_rate': {'values': [0.001, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'char_embd_dim': {'values': [64, 128, 256]},\n        'number_of_layers': {'values': [1, 2, 3, 4]},\n        'optimizer': {'values': ['nadam', 'adam']},\n        'cell_type': {'values': [\"RNN\", \"LSTM\", \"GRU\"]},\n        'hidden_layer_neurons': {'values': [128, 256, 512]},\n        'dropout': {'values': [0, 0.2, 0.3]}\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_params, project=\"DA6401_Assignment_3\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    wandb.init(project=\"DA6401_Assignment_3\")\n    config = wandb.config\n    with wandb.init(project=\"DA6401_Assignment_3\", name=f\"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}\", config=config):\n        train_dataloader, val_dataloader, data = prepare_dataloaders(train_source, train_target, val_source, val_target, config)\n        train(config, data, device, train_dataloader, val_dataloader)\n\nwandb.agent(sweep_id, function=main, count=70)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}