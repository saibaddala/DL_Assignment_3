{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11760006,"sourceType":"datasetVersion","datasetId":7382666}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nimport random\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:44:30.072138Z","iopub.execute_input":"2025-05-10T13:44:30.072368Z","iopub.status.idle":"2025-05-10T13:44:38.132153Z","shell.execute_reply.started":"2025-05-10T13:44:30.072342Z","shell.execute_reply":"2025-05-10T13:44:38.131089Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"3117f688d100f7889a8f97ba664299887fe48de1\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the device for training to CUDA if available, otherwise CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# Define special tokens for start, end, and padding\nEND_TOKEN = '>'\nSTART_TOKEN = '<'\nPAD_TOKEN = '_'\n\n# Define the teacher forcing ratio, which determines the probability of using teacher forcing during training\nTEACHER_FORCING_RATIO = 0.5\n\n# Paths to the training, testing, and validation CSV files\ntrain_csv = \"../input/telugu/te_train.csv\"\ntest_csv = \"../input/telugu/te_test.csv\"\nval_csv = \"../input/telugu/te_val.csv\"\n\n# Load the training data from the CSV file into a DataFrame\ntrain_df = pd.read_csv(train_csv, header=None)\n\n# Separate the source and target sequences from the training DataFrame\ntrain_source, train_target = train_df[0].to_numpy(), train_df[1].to_numpy()\n\n# Load the testing and validation data from the respective CSV files into DataFrames\ntest_df = pd.read_csv(test_csv, header=None)\nval_df = pd.read_csv(val_csv, header=None)\n\n# Separate the source and target sequences from the validation DataFrame\nval_source, val_target = val_df[0].to_numpy(), val_df[1].to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to add padding to source sequences\ndef add_padding(source_data, MAX_LENGTH):\n    padded_source_strings = []\n    for i in range(len(source_data)):\n        # Add start and end tokens to source sequence\n        source_str = START_TOKEN + source_data[i] + END_TOKEN\n        # Truncate or pad source sequence\n        source_str = source_str[:MAX_LENGTH]\n        source_str += PAD_TOKEN * (MAX_LENGTH - len(source_str))\n\n        padded_source_strings.append(source_str)\n        \n    return padded_source_strings\n\n# Function to convert source strings to sequences of indexes\ndef generate_string_to_sequence(source_data, source_char_index_dict):\n    source_sequences = []\n    for i in range(len(source_data)):\n        # Convert characters to indexes using the provided dictionary\n        source_sequences.append(get_chars(source_data[i], source_char_index_dict))\n    # Pad sequences to the same length\n    source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=2)\n    return source_sequences\n\n# Function to convert characters to their corresponding indexes\ndef get_chars(string, char_index_dict):\n    chars_indexes = []\n    for char in string:\n        # Map characters to their corresponding indexes using the provided dictionary\n        chars_indexes.append(char_index_dict[char])\n    return torch.tensor(chars_indexes, device=device)\n\n# Preprocess the data, including adding padding, generating sequences, and updating dictionaries\ndef preprocess_data(source_data, target_data):\n    data = {\n        \"source_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"target_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"source_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"source_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"target_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"target_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"source_len\": 3,\n        \"target_len\": 3,\n        \"source_data\": source_data,\n        \"target_data\": target_data,\n        \"source_data_seq\": [],\n        \"target_data_seq\": []\n    }\n    \n    # Calculate the maximum length of input and output sequences\n    data[\"INPUT_MAX_LENGTH\"] = max(len(string) for string in source_data) + 2\n    data[\"OUTPUT_MAX_LENGTH\"] = max(len(string) for string in target_data) + 2\n\n    # Pad the source and target sequences and update character dictionaries\n    padded_source_strings = add_padding(source_data, data[\"INPUT_MAX_LENGTH\"])\n    padded_target_strings = add_padding(target_data, data[\"OUTPUT_MAX_LENGTH\"])\n    \n    for i in range(len(padded_source_strings)):\n        for c in padded_source_strings[i]:\n            if data[\"source_char_index\"].get(c) is None:\n                data[\"source_chars\"].append(c)\n                idx = len(data[\"source_chars\"]) - 1\n                data[\"source_char_index\"][c] = idx\n                data[\"source_index_char\"][idx] = c\n        for c in padded_target_strings[i]:\n            if data[\"target_char_index\"].get(c) is None:\n                data[\"target_chars\"].append(c)\n                idx = len(data[\"target_chars\"]) - 1\n                data[\"target_char_index\"][c] = idx\n                data[\"target_index_char\"][idx] = c\n\n    # Generate sequences of indexes for source and target data\n    data['source_data_seq'] = generate_string_to_sequence(padded_source_strings, data['source_char_index'])\n    data['target_data_seq'] = generate_string_to_sequence(padded_target_strings, data['target_char_index'])\n    \n\n    # Update lengths of source and target character lists\n    data[\"source_len\"] = len(data[\"source_chars\"])\n    data[\"target_len\"] = len(data[\"target_chars\"])\n    \n    return data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:26.805644Z","iopub.execute_input":"2025-05-10T13:48:26.806141Z","iopub.status.idle":"2025-05-10T13:48:26.816353Z","shell.execute_reply.started":"2025-05-10T13:48:26.806118Z","shell.execute_reply":"2025-05-10T13:48:26.815720Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function to get the appropriate cell type based on the input string\ndef get_cell_type(cell_type):\n    if cell_type == \"RNN\":\n        return nn.RNN\n    elif cell_type == \"LSTM\":\n        return nn.LSTM\n    elif cell_type == \"GRU\":\n        return nn.GRU\n    else:\n        print(\"Specify correct cell type\")\n\n# Encoder module for the seq2seq model\nclass Encoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super(Encoder, self).__init__()\n        # Embedding layer for input data\n        self.embedding = nn.Embedding(data[\"source_len\"], h_params[\"char_embd_dim\"])\n        # Dropout layer for regularization\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        # Cell type chosen for encoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"], dropout=h_params[\"dropout\"], batch_first=True)\n        self.device = device\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        # Embedding input\n        embd_input = self.embedding(current_input)\n        embd_input = self.dropout(embd_input)\n        # Encoding step\n        output, prev_state = self.cell(embd_input, prev_state)\n        return output, prev_state\n\n    # Initialize initial state of the encoder\n    def getInitialState(self):\n        return torch.zeros(self.h_params[\"number_of_layers\"], self.h_params[\"batch_size\"], self.h_params[\"hidden_layer_neurons\"], device=self.device)\n\n# Decoder module for the seq2seq model\nclass Decoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super(Decoder, self).__init__()\n        # Embedding layer for target data\n        self.embedding = nn.Embedding(data[\"target_len\"], h_params[\"char_embd_dim\"])\n        # Dropout layer for regularization\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        # Cell type chosen for decoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"], dropout=h_params[\"dropout\"], batch_first=True)\n        # Fully connected layer for output\n        self.fc = nn.Linear(h_params[\"hidden_layer_neurons\"], data[\"target_len\"])\n        # Softmax layer for probability distribution\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        # Embedding input\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        curr_embd = self.dropout(curr_embd)\n        # Decoding step\n        output, prev_state = self.cell(curr_embd, prev_state)\n        # Apply softmax to output\n        output = self.softmax(self.fc(output))\n        return output, prev_state\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:35.635500Z","iopub.execute_input":"2025-05-10T13:48:35.636103Z","iopub.status.idle":"2025-05-10T13:48:35.644976Z","shell.execute_reply.started":"2025-05-10T13:48:35.636078Z","shell.execute_reply":"2025-05-10T13:48:35.644210Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Custom dataset class for handling source and target sequences\nclass MyDataset(Dataset):\n    def __init__(self, data):\n        # Initialize with source and target sequences\n        self.source_data_seq = data[0]\n        self.target_data_seq = data[1]\n    \n    def __len__(self):\n        # Return the length of the dataset\n        return len(self.source_data_seq)\n    \n    def __getitem__(self, idx):\n        # Get source and target data at the specified index\n        source_data = self.source_data_seq[idx]\n        target_data = self.target_data_seq[idx]\n        return source_data, target_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:44.312448Z","iopub.execute_input":"2025-05-10T13:48:44.312989Z","iopub.status.idle":"2025-05-10T13:48:44.317392Z","shell.execute_reply.started":"2025-05-10T13:48:44.312966Z","shell.execute_reply":"2025-05-10T13:48:44.316668Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Function for inference on the trained model\ndef inference(encoder, decoder, source_sequence, target_tensor, data, device, h_params, loss_fn, batch_num):\n    # Set encoder and decoder to evaluation mode\n    encoder.eval()\n    decoder.eval()\n    \n    # Initialize loss and correct predictions\n    loss = 0\n    correct = 0\n    \n    # Turn off gradient calculation\n    with torch.no_grad():\n        # Initialize encoder hidden state\n        encoder_hidden = encoder.getInitialState()\n        # For LSTM, initialize cell state as well\n        if h_params[\"cell_type\"] == \"LSTM\":\n            encoder_hidden = (encoder_hidden, encoder.getInitialState())\n        # Perform encoding\n        encoder_outputs, encoder_hidden = encoder(source_sequence, encoder_hidden)\n\n        # Initialize decoder input with start token\n        decoder_input_tensor = torch.full((h_params[\"batch_size\"], 1), data['target_char_index'][START_TOKEN], device=device)\n        decoder_actual_output = []\n        \n        # Initialize decoder hidden state with encoder hidden state\n        decoder_hidden = encoder_hidden\n        \n        # Iterate over each output time step\n        for di in range(data[\"OUTPUT_MAX_LENGTH\"]):\n            curr_target_chars = target_tensor[:, di]\n            # Perform decoding for one time step\n            decoder_output, decoder_hidden = decoder(decoder_input_tensor, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input_tensor = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_input_tensor)\n            decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                        \n            decoder_output = decoder_output[:, -1, :]\n            # Compute loss for the current time step\n            loss += (loss_fn(decoder_output, curr_target_chars))\n\n        # Concatenate decoder outputs\n        decoder_actual_output = torch.cat(decoder_actual_output, dim=0).view(data[\"OUTPUT_MAX_LENGTH\"], h_params[\"batch_size\"]).transpose(0, 1)\n\n        # Compute number of correct predictions\n        correct = (decoder_actual_output == target_tensor).all(dim=1).sum().item()\n\n        return correct, loss.item() / data[\"OUTPUT_MAX_LENGTH\"]\n\n# Function to evaluate the model on validation or test data\ndef evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn):\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    \n    # Iterate over each batch\n    for batch_num, (source_sequence, target_sequence) in enumerate(dataloader):\n        input_tensor = source_sequence\n        target_tensor = target_sequence\n        \n        # Perform inference on the batch\n        correct, loss = inference(encoder, decoder, input_tensor, target_tensor, data, device, h_params, loss_fn, batch_num)\n        \n        correct_predictions += correct\n        total_loss += loss\n    \n    # Compute accuracy and average loss\n    accuracy = correct_predictions / total_predictions\n    total_loss /= number_of_batches\n    \n    return accuracy, total_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:54.213420Z","iopub.execute_input":"2025-05-10T13:48:54.213695Z","iopub.status.idle":"2025-05-10T13:48:54.222000Z","shell.execute_reply.started":"2025-05-10T13:48:54.213659Z","shell.execute_reply":"2025-05-10T13:48:54.221304Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Function to create strings from indexes\ndef make_strings(data, source, target, output):\n    source_string = \"\"\n    target_string = \"\"\n    output_string = \"\"\n    # Convert source indexes to characters\n    for i in source:\n        source_string += (data['source_index_char'][i.item()])\n    # Convert target indexes to characters\n    for i in target:\n        target_string += (data['target_index_char'][i.item()])\n    # Convert output indexes to characters\n    for i in output:\n        output_string += (data['target_index_char'][i.item()])\n    return source_string, target_string, output_string\n\n# Training loop\ndef train_loop(encoder, decoder, h_params, data, data_loader, val_dataloader, device):\n    # Choose optimizer based on the specified type\n    if h_params[\"optimizer\"] == \"adam\":\n        encoder_optimizer = optim.Adam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.Adam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    elif h_params[\"optimizer\"] == \"nadam\":\n        encoder_optimizer = optim.NAdam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n        decoder_optimizer = optim.NAdam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    \n    total_predictions = len(data_loader.dataset)\n    total_batches = len(data_loader)\n    loss_fn = nn.NLLLoss()\n    \n    # Loop through each epoch\n    for ep in range(h_params[\"epochs\"]):\n        encoder.train()\n        decoder.train()\n        total_loss = 0\n        total_correct = 0\n        \n        # Loop through each batch\n        for batch_num, (source_batch, target_batch) in enumerate(data_loader):\n            # Get initial state of the encoder\n            encoder_initial_state = encoder.getInitialState()\n            if h_params[\"cell_type\"] == \"LSTM\":\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n            \n            encoder_current_state = encoder_initial_state\n            encoder_output, encoder_current_state = encoder(source_batch, encoder_current_state)\n            loss = 0\n            correct = 0\n            decoder_curr_state = encoder_current_state\n            output_seq_len = data[\"OUTPUT_MAX_LENGTH\"]\n            decoder_actual_output = []\n            \n            # Determine whether to use teacher forcing\n            use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n\n            # Loop through each output time step\n            for i in range(data[\"OUTPUT_MAX_LENGTH\"]):\n                if(i == 0):\n                    decoder_input_tensor = target_batch[:, i].view(h_params[\"batch_size\"], 1)\n                curr_target_chars = target_batch[:, i]\n                decoder_output, decoder_curr_state = decoder(decoder_input_tensor, decoder_curr_state)\n                topv, topi = decoder_output.topk(1)\n                decoder_input_tensor = topi.squeeze().detach()\n                decoder_actual_output.append(decoder_input_tensor)\n                if(i < output_seq_len - 1):\n                    if use_teacher_forcing:\n                        decoder_input_tensor = target_batch[:, i + 1].view(h_params[\"batch_size\"], 1)\n                    else:\n                        decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                decoder_output = decoder_output[:, -1, :]\n                loss += (loss_fn(decoder_output, curr_target_chars))\n\n            decoder_actual_output = torch.cat(decoder_actual_output, dim=0).view(output_seq_len, h_params[\"batch_size\"]).transpose(0, 1)\n            \n            correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            total_correct += correct\n            total_loss += loss.item() / output_seq_len\n            \n            # Backpropagation and optimization step\n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            loss.backward()\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n        \n        train_acc = total_correct / total_predictions\n        train_loss = total_loss / total_batches\n        \n        # Evaluate on validation set\n        val_acc, val_loss = evaluate(encoder, decoder, data, val_dataloader, device, h_params, loss_fn)\n        \n        # Log metrics\n        print(\"ep: \", ep, \" train acc:\", train_acc, \" train loss:\", train_loss, \" val acc:\", val_acc, \" val loss:\", val_loss)\n        wandb.log({\"train_accuracy\": train_acc, \"train_loss\": train_loss, \"val_accuracy\": val_acc, \"val_loss\": val_loss, \"epoch\": ep})\n\n    return encoder, decoder, loss_fn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:49:39.274817Z","iopub.execute_input":"2025-05-10T13:49:39.275287Z","iopub.status.idle":"2025-05-10T13:49:39.287471Z","shell.execute_reply.started":"2025-05-10T13:49:39.275263Z","shell.execute_reply":"2025-05-10T13:49:39.286809Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Training function\ndef train(h_params, data, device, train_dataloader, val_dataloader):\n    # Initialize encoder and decoder\n    encoder = Encoder(h_params, data, device).to(device)\n    decoder = Decoder(h_params, data, device).to(device)\n    \n    # Perform training loop\n    encoder, decoder, loss_fn = train_loop(encoder, decoder, h_params, data, train_dataloader, val_dataloader, device)\n    return encoder, decoder, loss_fn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:49:48.987550Z","iopub.execute_input":"2025-05-10T13:49:48.988170Z","iopub.status.idle":"2025-05-10T13:49:48.992432Z","shell.execute_reply.started":"2025-05-10T13:49:48.988149Z","shell.execute_reply":"2025-05-10T13:49:48.991691Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Function to prepare dataloaders for training and validation\ndef prepare_dataloaders(train_source, train_target, val_source, val_target, h_params):\n    # Preprocess training data\n    data = preprocess_data(copy.copy(train_source), copy.copy(train_target))\n    training_data = [data[\"source_data_seq\"], data['target_data_seq']]\n    # Create training dataset and dataloader\n    train_dataset = MyDataset(training_data)\n    train_dataloader = DataLoader(train_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n\n    # Preprocess validation data\n    val_padded_source_strings = add_padding(val_source, data[\"INPUT_MAX_LENGTH\"])\n    val_padded_target_strings = add_padding(val_target, data[\"OUTPUT_MAX_LENGTH\"])\n    val_source_sequences = generate_string_to_sequence(val_padded_source_strings, data['source_char_index'])\n    val_target_sequences = generate_string_to_sequence(val_padded_target_strings, data['target_char_index'])\n    validation_data = [val_source_sequences, val_target_sequences]\n    # Create validation dataset and dataloader\n    val_dataset = MyDataset(validation_data)\n    val_dataloader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=True)\n    return train_dataloader, val_dataloader, data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:50:10.479058Z","iopub.execute_input":"2025-05-10T13:50:10.479767Z","iopub.status.idle":"2025-05-10T13:50:10.484705Z","shell.execute_reply.started":"2025-05-10T13:50:10.479735Z","shell.execute_reply":"2025-05-10T13:50:10.484016Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"sweep_params = {\n    'method': 'bayes',\n    'name': 'DA6401_DL_Assignment_3',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'val_accuracy',\n    },\n    'parameters': {\n        'epochs': {'values': [15, 20]},\n        'learning_rate': {'values': [0.001, 0.0001]},\n        'batch_size': {'values': [32, 64, 128]},\n        'char_embd_dim': {'values': [64, 128, 256]},\n        'number_of_layers': {'values': [1, 2, 3, 4]},\n        'optimizer': {'values': ['nadam', 'adam']},\n        'cell_type': {'values': ['RNN', 'LSTM', 'GRU']},\n        'hidden_layer_neurons': {'values': [128, 256, 512]},\n        'dropout': {'values': [0, 0.2, 0.3]}\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_params, project=\"DA6401_DL_Assignment_3\")\n\ndef main():\n    with wandb.init(project=\"DA6401_DL_Assignment_3\") as run:\n        config = wandb.config\n        run.name = f\"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}\"\n\n        train_dataloader, val_dataloader, data = prepare_dataloaders(train_source, train_target, val_source, val_target, config)\n        train(config, data, device, train_dataloader, val_dataloader)\n        \nwandb.agent(sweep_id, function=main)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:53:02.000299Z","iopub.execute_input":"2025-05-10T13:53:02.000633Z","iopub.status.idle":"2025-05-10T13:53:03.320192Z","shell.execute_reply.started":"2025-05-10T13:53:02.000604Z","shell.execute_reply":"2025-05-10T13:53:03.319598Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: z4d53uz3\nSweep URL: https://wandb.ai/cs23m059-iit-madras/DL_Assignment_3/sweeps/z4d53uz3\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}