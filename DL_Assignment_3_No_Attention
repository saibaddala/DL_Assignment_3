{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11761049,"sourceType":"datasetVersion","datasetId":7383378}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:12.780653Z","iopub.execute_input":"2025-05-10T20:08:12.780997Z","iopub.status.idle":"2025-05-10T20:08:19.314311Z","shell.execute_reply.started":"2025-05-10T20:08:12.780964Z","shell.execute_reply":"2025-05-10T20:08:19.313729Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"3117f688d100f7889a8f97ba664299887fe48de1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:19.315297Z","iopub.execute_input":"2025-05-10T20:08:19.315526Z","iopub.status.idle":"2025-05-10T20:08:25.222343Z","shell.execute_reply.started":"2025-05-10T20:08:19.315499Z","shell.execute_reply":"2025-05-10T20:08:25.221792Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m059\u001b[0m (\u001b[33mcs23m059-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:25.223045Z","iopub.execute_input":"2025-05-10T20:08:25.223407Z","iopub.status.idle":"2025-05-10T20:08:25.281134Z","shell.execute_reply.started":"2025-05-10T20:08:25.223390Z","shell.execute_reply":"2025-05-10T20:08:25.280424Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# File paths\ntrain_csv = \"/kaggle/input/telugu/te_train.csv\"\ntest_csv = \"/kaggle/input/telugu/te_test.csv\"\nval_csv = \"/kaggle/input/telugu/te_val.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:25.282635Z","iopub.execute_input":"2025-05-10T20:08:25.282843Z","iopub.status.idle":"2025-05-10T20:08:25.298570Z","shell.execute_reply.started":"2025-05-10T20:08:25.282826Z","shell.execute_reply":"2025-05-10T20:08:25.298007Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data loading\ntrain_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv, header=None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv, header=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:25.299432Z","iopub.execute_input":"2025-05-10T20:08:25.299690Z","iopub.status.idle":"2025-05-10T20:08:25.449621Z","shell.execute_reply.started":"2025-05-10T20:08:25.299665Z","shell.execute_reply":"2025-05-10T20:08:25.448826Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def pre_processing(train_input, train_output):\n    data = {\n        \"all_characters\": [],\n        \"char_num_map\": {},\n        \"num_char_map\": {},\n        \"source_charToNum\": torch.zeros(len(train_input), 30, dtype=torch.int, device=device),\n        \"source_data\": train_input,\n        \"all_characters_2\": [],\n        \"char_num_map_2\": {},\n        \"num_char_map_2\": {},\n        \"val_charToNum\": torch.zeros(len(train_output), 23, dtype=torch.int, device=device),\n        \"target_data\": train_output,\n        \"source_len\": 0,\n        \"target_len\": 0\n    }\n    \n    for i in range(len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\" * (29 - len(train_input[i]))\n        charToNum = []\n        for char in train_input[i]:\n            if char not in data[\"all_characters\"]:\n                data[\"all_characters\"].append(char)\n                index = len(data[\"all_characters\"]) - 1\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"char_num_map\"][char]\n            charToNum.append(index)\n        data[\"source_charToNum\"][i] = torch.tensor(charToNum, device=device)\n\n        train_output[i] = \"{\" + train_output[i] + \"}\" * (22 - len(train_output[i]))\n        charToNum1 = []\n        for char in train_output[i]:\n            if char not in data[\"all_characters_2\"]:\n                data[\"all_characters_2\"].append(char)\n                index = len(data[\"all_characters_2\"]) - 1\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"char_num_map_2\"][char]\n            charToNum1.append(index)\n        data[\"val_charToNum\"][i] = torch.tensor(charToNum1, device=device)\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n    return data\n\ndata = pre_processing(copy.copy(train_input), copy.copy(train_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:25.450460Z","iopub.execute_input":"2025-05-10T20:08:25.450771Z","iopub.status.idle":"2025-05-10T20:08:31.094320Z","shell.execute_reply.started":"2025-05-10T20:08:25.450749Z","shell.execute_reply":"2025-05-10T20:08:31.093752Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def pre_processing_validation(val_input, val_output):\n    data2 = {\n        \"source_charToNum\": torch.zeros(len(val_input), 30, dtype=torch.int, device=device),\n        \"val_charToNum\": torch.zeros(len(val_output), 23, dtype=torch.int, device=device)\n    }\n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\" * (29 - len(val_input[i]))\n        charToNum = [m1[char] for char in val_input[i]]\n        data2[\"source_charToNum\"][i] = torch.tensor(charToNum, device=device)\n        \n        val_output[i] = \"{\" + val_output[i] + \"}\" * (22 - len(val_output[i]))\n        charToNum1 = [m2[char] for char in val_output[i]]\n        data2[\"val_charToNum\"][i] = torch.tensor(charToNum1, device=device)\n    \n    return data2\n\ndata2 = pre_processing_validation(copy.copy(val_input), copy.copy(val_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:08:31.094991Z","iopub.execute_input":"2025-05-10T20:08:31.095168Z","iopub.status.idle":"2025-05-10T20:08:31.585472Z","shell.execute_reply.started":"2025-05-10T20:08:31.095154Z","shell.execute_reply":"2025-05-10T20:08:31.584931Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x, y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        return self.source[idx], self.target[idx]\n\ndef dataLoaderFun(dataName, batch_size):\n    if dataName == 'train':\n        dataset = MyDataset(data[\"source_charToNum\"], data['val_charToNum'])\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"], data2['val_charToNum'])\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\nclass Encoder(nn.Module):\n    def __init__(self, inputDim, embSize, encoderLayers, hiddenLayerNuerons, cellType, bidirection):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.bidirection = bidirection\n        self.num_directions = 2 if bidirection == \"Yes\" else 1\n\n        if cellType == 'GRU':\n            self.rnn = nn.GRU(embSize, hiddenLayerNuerons, \n                            num_layers=encoderLayers,\n                            bidirectional=(bidirection == \"Yes\"),\n                            batch_first=True)\n        elif cellType == 'LSTM':\n            self.rnn = nn.LSTM(embSize, hiddenLayerNuerons,\n                             num_layers=encoderLayers,\n                             bidirectional=(bidirection == \"Yes\"),\n                             batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize, hiddenLayerNuerons,\n                            num_layers=encoderLayers,\n                            bidirectional=(bidirection == \"Yes\"),\n                            batch_first=True)\n\n    def forward(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        return self.rnn(embdInput, prevState)\n\n    def getInitialState(self, batch_size):\n        return torch.zeros(self.encoderLayers * self.num_directions, \n                          batch_size, \n                          self.hiddenLayerNuerons, \n                          device=device)\n\nclass Decoder(nn.Module):\n    def __init__(self, outputDim, embSize, hiddenLayerNuerons, decoderLayers, cellType, dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n        self.decoderLayers = decoderLayers\n\n        if cellType == 'GRU':\n            self.rnn = nn.GRU(embSize, hiddenLayerNuerons,\n                            num_layers=decoderLayers,\n                            batch_first=True)\n        elif cellType == 'LSTM':\n            self.rnn = nn.LSTM(embSize, hiddenLayerNuerons,\n                             num_layers=decoderLayers,\n                             batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize, hiddenLayerNuerons,\n                            num_layers=decoderLayers,\n                            batch_first=True)\n\n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim)\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prevState = self.rnn(embdInput, prevState)\n        output = self.dropout(output)\n        output = self.softmax(self.fc(output))\n        return output, prevState\n\ndef init_decoder_state(encoder_state, encoderLayers, decoderLayers, cellType):\n    if cellType == 'LSTM':\n        h, c = encoder_state\n        if encoderLayers >= decoderLayers:\n            h_dec = h[-decoderLayers:]\n            c_dec = c[-decoderLayers:]\n        else:\n            h_dec = torch.cat([h] + [h[-1:]]*(decoderLayers-encoderLayers), dim=0)\n            c_dec = torch.cat([c] + [c[-1:]]*(decoderLayers-encoderLayers), dim=0)\n        return (h_dec, c_dec)\n    else:\n        h = encoder_state\n        if encoderLayers >= decoderLayers:\n            h_dec = h[-decoderLayers:]\n        else:\n            h_dec = torch.cat([h] + [h[-1:]]*(decoderLayers-encoderLayers), dim=0)\n        return h_dec\n\ndef train(embSize, encoderLayers, decoderLayers, hiddenLayerNuerons, cellType, bidirection, dropout, epochs, batchsize, learningRate, optimizer, tf_ratio):\n    dataLoader = dataLoaderFun(\"train\", batchsize)\n    lossFunction = nn.NLLLoss()\n    \n    encoder = Encoder(data[\"source_len\"], embSize, encoderLayers, \n                     hiddenLayerNuerons, cellType, bidirection).to(device)\n    decoder = Decoder(data[\"target_len\"], embSize, hiddenLayerNuerons,\n                     decoderLayers, cellType, dropout).to(device)\n\n    if optimizer == 'Adam':\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n\n    for epoch in range(epochs):\n        train_accuracy = 0\n        train_loss = 0\n        total_samples = 0\n        \n        for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n            current_batch_size = sourceBatch.size(0)\n            encoderInitialState = encoder.getInitialState(current_batch_size)\n            \n            if bidirection == \"Yes\":\n                reversed_batch = torch.flip(sourceBatch, dims=[1])\n                sourceBatch = (sourceBatch + reversed_batch) // 2\n            \n            if cellType == 'LSTM':\n                encoderInitialState = (encoderInitialState, \n                                      torch.zeros_like(encoderInitialState))\n\n            encoder_output, encoderCurrentState = encoder(sourceBatch, encoderInitialState)\n            \n            # Handle bidirectional state reduction\n            if bidirection == \"Yes\":\n                if cellType == 'LSTM':\n                    encoderCurrentState = (\n                        encoderCurrentState[0].view(encoderLayers, 2, current_batch_size, -1).sum(1),\n                        encoderCurrentState[1].view(encoderLayers, 2, current_batch_size, -1).sum(1)\n                    )\n                else:\n                    encoderCurrentState = encoderCurrentState.view(\n                        encoderLayers, 2, current_batch_size, -1\n                    ).sum(1)\n            \n            # Initialize decoder state\n            decoderCurrState = init_decoder_state(\n                encoderCurrentState, encoderLayers, decoderLayers, cellType\n            )\n            \n            loss = 0\n            sequenceLen = targetBatch.shape[1]\n            Output = []\n            randNumber = random.random()\n\n            for i in range(sequenceLen):\n                if i == 0:\n                    decoderInput = targetBatch[:, i].reshape(current_batch_size, 1)\n                else:\n                    if randNumber < tf_ratio:\n                        decoderInput = targetBatch[:, i].reshape(current_batch_size, 1)\n                    else:\n                        decoderInput = decoderInput.reshape(current_batch_size, 1)\n\n                decoderOutput, decoderCurrState = decoder(decoderInput, decoderCurrState)\n                _, topIndeces = decoderOutput.topk(1)\n                decoderOutput = decoderOutput[:, -1, :]\n                targetChars = targetBatch[:, i].type(dtype=torch.long)\n                loss += lossFunction(decoderOutput, targetChars)\n                decoderInput = topIndeces.squeeze().detach()\n                Output.append(decoderInput)\n\n            tensor_2d = torch.stack(Output)\n            Output = tensor_2d.t()\n            train_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n            train_loss += (loss.item() / sequenceLen)\n            total_samples += targetBatch.size(0)\n\n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n        \n        val_acc, val_loss = validationAccuracy(encoder, decoder, batchsize, tf_ratio, cellType, bidirection)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(dataLoader),\n            \"train_accuracy\": train_accuracy / total_samples,\n            \"validation_loss\": val_loss / len(dataLoaderFun(\"validation\", batchsize)),\n            \"validation_accuracy\": val_acc / sum(len(b) for b, _ in dataLoaderFun(\"validation\", batchsize))\n        })\n\ndef validationAccuracy(encoder, decoder, batchsize, tf_ratio, cellType, bidirection):\n    dataLoader = dataLoaderFun(\"validation\", batchsize)\n    encoder.eval()\n    decoder.eval()\n    validation_accuracy = 0\n    validation_loss = 0\n    total_samples = 0\n    lossFunction = nn.NLLLoss()\n\n    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n        current_batch_size = sourceBatch.size(0)\n        encoderInitialState = encoder.getInitialState(current_batch_size)\n        \n        if cellType == 'LSTM':\n            encoderInitialState = (encoderInitialState, \n                                  torch.zeros_like(encoderInitialState))\n        \n        if bidirection == \"Yes\":\n            reversed_batch = torch.flip(sourceBatch, dims=[1])\n            sourceBatch = (sourceBatch + reversed_batch) // 2\n\n        encoder_output, encoderCurrentState = encoder(sourceBatch, encoderInitialState)\n        \n        # Handle bidirectional state reduction\n        if bidirection == \"Yes\":\n            if cellType == 'LSTM':\n                encoderCurrentState = (\n                    encoderCurrentState[0].view(encoder.encoderLayers, 2, current_batch_size, -1).sum(1),\n                    encoderCurrentState[1].view(encoder.encoderLayers, 2, current_batch_size, -1).sum(1)\n                )\n            else:\n                encoderCurrentState = encoderCurrentState.view(\n                    encoder.encoderLayers, 2, current_batch_size, -1\n                ).sum(1)\n        \n        decoderCurrState = init_decoder_state(\n            encoderCurrentState, encoder.encoderLayers, decoder.decoderLayers, cellType\n        )\n        \n        loss = 0\n        outputSeqLen = targetBatch.shape[1]\n        Output = []\n        randNumber = random.random()\n\n        for i in range(outputSeqLen):\n            if i == 0:\n                decoderInputensor = targetBatch[:, i].reshape(current_batch_size, 1)\n            else:\n                if randNumber < tf_ratio:\n                    decoderInputensor = targetBatch[:, i].reshape(current_batch_size, 1)\n                else:\n                    decoderInputensor = decoderInputensor.reshape(current_batch_size, 1)\n\n            decoderOutput, decoderCurrState = decoder(decoderInputensor, decoderCurrState)\n            _, topIndeces = decoderOutput.topk(1)\n            decoderOutput = decoderOutput[:, -1, :]\n            curr_target_chars = targetBatch[:, i].type(dtype=torch.long)\n            loss += lossFunction(decoderOutput, curr_target_chars)\n            decoderInputensor = topIndeces.squeeze().detach()\n            Output.append(decoderInputensor)\n\n        tensor_2d = torch.stack(Output)\n        Output = tensor_2d.t()\n        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n        validation_loss += (loss.item() / outputSeqLen)\n        total_samples += targetBatch.size(0)\n\n    encoder.train()\n    decoder.train()\n    return validation_accuracy, validation_loss","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-10T20:11:28.333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project='DA6401_Assignment_3')\n    params = wandb.config\n    train(params.embSize, params.encoderLayers, params.decoderLayers,\n          params.hiddenLayerNuerons, params.cellType, params.bidirection,\n          params.dropout, params.epochs, params.batchsize, params.learningRate,\n          params.optimizer, params.tf_ratio)\n\nsweep_params = {\n    'method': 'bayes',\n    'name': 'DA6401_Assignment_3',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'validation_accuracy',\n    },\n    'parameters': {\n        'embSize': {'values': [16, 32, 64]},\n        'encoderLayers': {'values': [1, 5, 10]},\n        'decoderLayers': {'values': [1, 5, 10]},\n        'hiddenLayerNuerons': {'values': [64, 256, 512]},\n        'cellType': {'values': ['GRU', 'RNN', 'LSTM']},\n        'bidirection': {'values': ['no', 'Yes']},\n        'dropout': {'values': [0, 0.2, 0.3]},\n        'epochs': {'values': [10, 15]},\n        'batchsize': {'values': [32, 64]},\n        'learningRate': {'values': [1e-2, 1e-3, 1e-4]},\n        'optimizer': {'values': ['Adam', 'Nadam']},\n        'tf_ratio': {'values': [0.2, 0.4, 0.5]}\n    }\n}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-10T20:11:28.333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweepId = wandb.sweep(sweep_params, project='DA6401_Assignment_3')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-10T20:11:28.333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.agent(sweepId, function=main_fun, count=100)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-10T20:11:28.333Z"}},"outputs":[],"execution_count":null}]}