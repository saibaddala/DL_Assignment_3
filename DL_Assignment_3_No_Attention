{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11760006,"sourceType":"datasetVersion","datasetId":7382666}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nimport random\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:44:30.072138Z","iopub.execute_input":"2025-05-10T13:44:30.072368Z","iopub.status.idle":"2025-05-10T13:44:38.132153Z","shell.execute_reply.started":"2025-05-10T13:44:30.072342Z","shell.execute_reply":"2025-05-10T13:44:38.131089Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"3117f688d100f7889a8f97ba664299887fe48de1\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the device for training to CUDA if available, otherwise CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# Define special tokens for start, end, and padding\nEND_TOKEN = '>'\nSTART_TOKEN = '<'\nPAD_TOKEN = '_'\n\n# Define the teacher forcing ratio, which determines the probability of using teacher forcing during training\nTEACHER_FORCING_RATIO = 0.5\n\n# Paths to the training, testing, and validation CSV files\ntrain_csv = \"../input/telugu/te_train.csv\"\ntest_csv = \"../input/telugu/te_test.csv\"\nval_csv = \"../input/telugu/te_val.csv\"\n\n# Load the training data from the CSV file into a DataFrame\ntrain_df = pd.read_csv(train_csv, header=None)\n\n# Separate the source and target sequences from the training DataFrame\ntrain_source, train_target = train_df[0].to_numpy(), train_df[1].to_numpy()\n\n# Load the testing and validation data from the respective CSV files into DataFrames\ntest_df = pd.read_csv(test_csv, header=None)\nval_df = pd.read_csv(val_csv, header=None)\n\n# Separate the source and target sequences from the validation DataFrame\nval_source, val_target = val_df[0].to_numpy(), val_df[1].to_numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to add padding to source sequences\ndef add_padding(source_data, MAX_LENGTH):\n    padded_source_strings = []\n    for i in range(len(source_data)):\n        # Add start and end tokens to source sequence\n        source_str = START_TOKEN + source_data[i] + END_TOKEN\n        # Truncate or pad source sequence\n        source_str = source_str[:MAX_LENGTH]\n        source_str += PAD_TOKEN * (MAX_LENGTH - len(source_str))\n\n        padded_source_strings.append(source_str)\n        \n    return padded_source_strings\n\n# Function to convert source strings to sequences of indexes\ndef generate_string_to_sequence(source_data, source_char_index_dict):\n    source_sequences = []\n    for i in range(len(source_data)):\n        # Convert characters to indexes using the provided dictionary\n        source_sequences.append(get_chars(source_data[i], source_char_index_dict))\n    # Pad sequences to the same length\n    source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=2)\n    return source_sequences\n\n# Function to convert characters to their corresponding indexes\ndef get_chars(string, char_index_dict):\n    chars_indexes = []\n    for char in string:\n        # Map characters to their corresponding indexes using the provided dictionary\n        chars_indexes.append(char_index_dict[char])\n    return torch.tensor(chars_indexes, device=device)\n\n# Preprocess the data, including adding padding, generating sequences, and updating dictionaries\ndef preprocess_data(source_data, target_data):\n    data = {\n        \"source_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"target_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"source_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"source_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"target_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"target_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"source_len\": 3,\n        \"target_len\": 3,\n        \"source_data\": source_data,\n        \"target_data\": target_data,\n        \"source_data_seq\": [],\n        \"target_data_seq\": []\n    }\n    \n    # Calculate the maximum length of input and output sequences\n    data[\"INPUT_MAX_LENGTH\"] = max(len(string) for string in source_data) + 2\n    data[\"OUTPUT_MAX_LENGTH\"] = max(len(string) for string in target_data) + 2\n\n    # Pad the source and target sequences and update character dictionaries\n    padded_source_strings = add_padding(source_data, data[\"INPUT_MAX_LENGTH\"])\n    padded_target_strings = add_padding(target_data, data[\"OUTPUT_MAX_LENGTH\"])\n    \n    for i in range(len(padded_source_strings)):\n        for c in padded_source_strings[i]:\n            if data[\"source_char_index\"].get(c) is None:\n                data[\"source_chars\"].append(c)\n                idx = len(data[\"source_chars\"]) - 1\n                data[\"source_char_index\"][c] = idx\n                data[\"source_index_char\"][idx] = c\n        for c in padded_target_strings[i]:\n            if data[\"target_char_index\"].get(c) is None:\n                data[\"target_chars\"].append(c)\n                idx = len(data[\"target_chars\"]) - 1\n                data[\"target_char_index\"][c] = idx\n                data[\"target_index_char\"][idx] = c\n\n    # Generate sequences of indexes for source and target data\n    data['source_data_seq'] = generate_string_to_sequence(padded_source_strings, data['source_char_index'])\n    data['target_data_seq'] = generate_string_to_sequence(padded_target_strings, data['target_char_index'])\n    \n\n    # Update lengths of source and target character lists\n    data[\"source_len\"] = len(data[\"source_chars\"])\n    data[\"target_len\"] = len(data[\"target_chars\"])\n    \n    return data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:26.805644Z","iopub.execute_input":"2025-05-10T13:48:26.806141Z","iopub.status.idle":"2025-05-10T13:48:26.816353Z","shell.execute_reply.started":"2025-05-10T13:48:26.806118Z","shell.execute_reply":"2025-05-10T13:48:26.815720Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function to get the appropriate cell type based on the input string\ndef get_cell_type(cell_type):\n    if cell_type == \"RNN\":\n        return nn.RNN\n    elif cell_type == \"LSTM\":\n        return nn.LSTM\n    elif cell_type == \"GRU\":\n        return nn.GRU\n    else:\n        print(\"Specify correct cell type\")\n\n# Encoder module for the seq2seq model\nclass Encoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super(Encoder, self).__init__()\n        # Embedding layer for input data\n        self.embedding = nn.Embedding(data[\"source_len\"], h_params[\"char_embd_dim\"])\n        # Dropout layer for regularization\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        # Cell type chosen for encoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"], dropout=h_params[\"dropout\"], batch_first=True)\n        self.device = device\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        # Embedding input\n        embd_input = self.embedding(current_input)\n        embd_input = self.dropout(embd_input)\n        # Encoding step\n        output, prev_state = self.cell(embd_input, prev_state)\n        return output, prev_state\n\n    # Initialize initial state of the encoder\n    def getInitialState(self):\n        return torch.zeros(self.h_params[\"number_of_layers\"], self.h_params[\"batch_size\"], self.h_params[\"hidden_layer_neurons\"], device=self.device)\n\n# Decoder module for the seq2seq model\nclass Decoder(nn.Module):\n    def __init__(self, h_params, data, device):\n        super(Decoder, self).__init__()\n        # Embedding layer for target data\n        self.embedding = nn.Embedding(data[\"target_len\"], h_params[\"char_embd_dim\"])\n        # Dropout layer for regularization\n        self.dropout = nn.Dropout(h_params[\"dropout\"])\n        # Cell type chosen for decoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],\n                                                         num_layers=h_params[\"number_of_layers\"], dropout=h_params[\"dropout\"], batch_first=True)\n        # Fully connected layer for output\n        self.fc = nn.Linear(h_params[\"hidden_layer_neurons\"], data[\"target_len\"])\n        # Softmax layer for probability distribution\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.h_params = h_params\n\n    def forward(self, current_input, prev_state):\n        # Embedding input\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        curr_embd = self.dropout(curr_embd)\n        # Decoding step\n        output, prev_state = self.cell(curr_embd, prev_state)\n        # Apply softmax to output\n        output = self.softmax(self.fc(output))\n        return output, prev_state\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:35.635500Z","iopub.execute_input":"2025-05-10T13:48:35.636103Z","iopub.status.idle":"2025-05-10T13:48:35.644976Z","shell.execute_reply.started":"2025-05-10T13:48:35.636078Z","shell.execute_reply":"2025-05-10T13:48:35.644210Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Custom dataset class for handling source and target sequences\nclass MyDataset(Dataset):\n    def __init__(self, data):\n        # Initialize with source and target sequences\n        self.source_data_seq = data[0]\n        self.target_data_seq = data[1]\n    \n    def __len__(self):\n        # Return the length of the dataset\n        return len(self.source_data_seq)\n    \n    def __getitem__(self, idx):\n        # Get source and target data at the specified index\n        source_data = self.source_data_seq[idx]\n        target_data = self.target_data_seq[idx]\n        return source_data, target_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:44.312448Z","iopub.execute_input":"2025-05-10T13:48:44.312989Z","iopub.status.idle":"2025-05-10T13:48:44.317392Z","shell.execute_reply.started":"2025-05-10T13:48:44.312966Z","shell.execute_reply":"2025-05-10T13:48:44.316668Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Function for inference on the trained model\ndef inference(encoder, decoder, source_sequence, target_tensor, data, device, h_params, loss_fn, batch_num):\n    # Set encoder and decoder to evaluation mode\n    encoder.eval()\n    decoder.eval()\n    \n    # Initialize loss and correct predictions\n    loss = 0\n    correct = 0\n    \n    # Turn off gradient calculation\n    with torch.no_grad():\n        # Initialize encoder hidden state\n        encoder_hidden = encoder.getInitialState()\n        # For LSTM, initialize cell state as well\n        if h_params[\"cell_type\"] == \"LSTM\":\n            encoder_hidden = (encoder_hidden, encoder.getInitialState())\n        # Perform encoding\n        encoder_outputs, encoder_hidden = encoder(source_sequence, encoder_hidden)\n\n        # Initialize decoder input with start token\n        decoder_input_tensor = torch.full((h_params[\"batch_size\"], 1), data['target_char_index'][START_TOKEN], device=device)\n        decoder_actual_output = []\n        \n        # Initialize decoder hidden state with encoder hidden state\n        decoder_hidden = encoder_hidden\n        \n        # Iterate over each output time step\n        for di in range(data[\"OUTPUT_MAX_LENGTH\"]):\n            curr_target_chars = target_tensor[:, di]\n            # Perform decoding for one time step\n            decoder_output, decoder_hidden = decoder(decoder_input_tensor, decoder_hidden)\n            topv, topi = decoder_output.topk(1)\n            decoder_input_tensor = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_input_tensor)\n            decoder_input_tensor = decoder_input_tensor.view(h_params[\"batch_size\"], 1)\n                        \n            decoder_output = decoder_output[:, -1, :]\n            # Compute loss for the current time step\n            loss += (loss_fn(decoder_output, curr_target_chars))\n\n        # Concatenate decoder outputs\n        decoder_actual_output = torch.cat(decoder_actual_output, dim=0).view(data[\"OUTPUT_MAX_LENGTH\"], h_params[\"batch_size\"]).transpose(0, 1)\n\n        # Compute number of correct predictions\n        correct = (decoder_actual_output == target_tensor).all(dim=1).sum().item()\n\n        return correct, loss.item() / data[\"OUTPUT_MAX_LENGTH\"]\n\n# Function to evaluate the model on validation or test data\ndef evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn):\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    \n    # Iterate over each batch\n    for batch_num, (source_sequence, target_sequence) in enumerate(dataloader):\n        input_tensor = source_sequence\n        target_tensor = target_sequence\n        \n        # Perform inference on the batch\n        correct, loss = inference(encoder, decoder, input_tensor, target_tensor, data, device, h_params, loss_fn, batch_num)\n        \n        correct_predictions += correct\n        total_loss += loss\n    \n    # Compute accuracy and average loss\n    accuracy = correct_predictions / total_predictions\n    total_loss /= number_of_batches\n    \n    return accuracy, total_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T13:48:54.213420Z","iopub.execute_input":"2025-05-10T13:48:54.213695Z","iopub.status.idle":"2025-05-10T13:48:54.222000Z","shell.execute_reply.started":"2025-05-10T13:48:54.213659Z","shell.execute_reply":"2025-05-10T13:48:54.221304Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}