{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11763850,"sourceType":"datasetVersion","datasetId":7385249}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(key=\"3117f688d100f7889a8f97ba664299887fe48de1\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# File paths\ntrain_csv = \"/kaggle/input/telugu/te_train.csv\"\ntest_csv = \"/kaggle/input/telugu/te_test.csv\"\nval_csv = \"/kaggle/input/telugu/te_val.csv\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv, header=None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv, header=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pre_processing(train_input, train_output):\n    data = {\n        \"all_characters\": [],\n        \"char_num_map\": {},\n        \"num_char_map\": {},\n        \"source_charToNum\": torch.zeros(len(train_input), 30, dtype=torch.int, device=device),\n        \"source_data\": train_input,\n        \"all_characters_2\": [],\n        \"char_num_map_2\": {},\n        \"num_char_map_2\": {},\n        \"val_charToNum\": torch.zeros(len(train_output), 23, dtype=torch.int, device=device),\n        \"target_data\": train_output,\n        \"source_len\": 0,\n        \"target_len\": 0\n    }\n    k = 0\n    for i in range(len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\" * (29 - len(train_input[i]))\n        charToNum = []\n        for char in train_input[i]:\n            if char not in data[\"all_characters\"]:\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            charToNum.append(index)\n        my_tensor = torch.tensor(charToNum, device=device)\n        data[\"source_charToNum\"][k] = my_tensor\n\n        charToNum1 = []\n        train_output[i] = \"{\" + train_output[i] + \"}\" * (22 - len(train_output[i]))\n        for char in train_output[i]:\n            if char not in data[\"all_characters_2\"]:\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n            charToNum1.append(index)\n        my_tensor1 = torch.tensor(charToNum1, device=device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        k += 1\n\n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n    return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input), copy.copy(train_output))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pre_processing_validation(val_input, val_output):\n    data2 = {\n        \"all_characters\": [],\n        \"char_num_map\": {},\n        \"num_char_map\": {},\n        \"source_charToNum\": torch.zeros(len(val_input), 30, dtype=torch.int, device=device),\n        \"source_data\": val_input,\n        \"all_characters_2\": [],\n        \"char_num_map_2\": {},\n        \"num_char_map_2\": {},\n        \"val_charToNum\": torch.zeros(len(val_output), 23, dtype=torch.int, device=device),\n        \"target_data\": val_output,\n        \"source_len\": 0,\n        \"target_len\": 0\n    }\n    k = 0\n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    for i in range(len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\" * (29 - len(val_input[i]))\n        charToNum = []\n        for char in val_input[i]:\n            if char not in data2[\"all_characters\"]:\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            charToNum.append(index)\n        my_tensor = torch.tensor(charToNum, device=device)\n        data2[\"source_charToNum\"][k] = my_tensor\n\n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\" * (22 - len(val_output[i]))\n        for char in val_output[i]:\n            if char not in data2[\"all_characters_2\"]:\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n            charToNum1.append(index)\n        my_tensor1 = torch.tensor(charToNum1, device=device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        k += 1\n\n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n    return data2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data2 = pre_processing_validation(copy.copy(val_input), copy.copy(val_output))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x, y):\n        self.source = x\n        self.target = y\n\n    def __len__(self):\n        return len(self.source)\n\n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data\n\ndef validationAccuracy(encoder, decoder, batchsize, tf_ratio, cellType, bidirection):\n    dataLoader = dataLoaderFun(\"validation\", batchsize)\n    encoder.eval()\n    decoder.eval()\n    total_sequences = 0\n    total_correct_sequences = 0\n    total_char_matches = 0\n    total_characters = 0\n    total_loss = 0\n\n    lossFunction = nn.NLLLoss()\n\n    for source_batch, target_batch in dataLoader:\n        actual_batch_size = source_batch.shape[0]\n        total_sequences += actual_batch_size\n        total_characters += target_batch.numel()\n\n        encoder_initial_state = encoder.getInitialState(actual_batch_size)\n        if bidirection == \"Yes\":\n            reversed_batch = torch.flip(source_batch, dims=[1])\n            source_batch = (source_batch + reversed_batch) // 2\n        if cellType == 'LSTM':\n            encoder_initial_state = (encoder_initial_state, encoder.getInitialState(actual_batch_size))\n\n        encoder_states, _ = encoder(source_batch, encoder_initial_state)\n        decoder_current_state = encoder_states[-1, :, :, :]\n        encoder_final_layer_states = encoder_states[:, -1, :, :]\n        output_seq_len = target_batch.shape[1]\n\n        loss = 0\n        decoder_actual_output = []\n        randNumber = random.random()\n\n        for i in range(output_seq_len):\n            if i == 0:\n                decoder_current_input = torch.full((actual_batch_size, 1), 0, device=device)\n            else:\n                if randNumber < tf_ratio:\n                    decoder_current_input = target_batch[:, i].reshape(actual_batch_size, 1)\n                else:\n                    decoder_current_input = decoder_current_input.reshape(actual_batch_size, 1)\n            decoder_output, decoder_current_state, _ = decoder(decoder_current_input, decoder_current_state, encoder_final_layer_states)\n            topv, topi = decoder_output.topk(1)\n            decoder_current_input = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_current_input)\n\n            decoder_output = decoder_output[:, -1, :]\n            curr_target_chars = target_batch[:, i].long()\n            loss += lossFunction(decoder_output, curr_target_chars)\n\n        total_loss += loss.item() / output_seq_len\n        decoder_actual_output = torch.cat(decoder_actual_output, dim=0).reshape(output_seq_len, actual_batch_size).transpose(0, 1)\n        total_correct_sequences += (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        total_char_matches += (decoder_actual_output == target_batch).sum().item()\n\n    encoder.train()\n    decoder.train()\n\n    wandb.log({\n        'validation_loss': total_loss / len(dataLoader),\n        'validation_accuracy': total_correct_sequences / total_sequences,\n        'validation_char_accuracy': total_char_matches / total_characters\n    })","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2, 1, 0)\n        keys = keys.permute(1, 0, 2)\n        context = torch.bmm(weights, keys)\n        return context, weights","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}